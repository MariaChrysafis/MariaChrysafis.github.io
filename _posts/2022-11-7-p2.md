---
layout: post
title: Treaps
classes: wide
comments: true
mermaid: true
---
# Binary Search Trees
Binary search trees are nothing more than *special* binary trees that satisfy what's called the **binary search tree property**:
- The keys in a node's **left** subtree is strictly **smaller** than the key of the node itself.
- The keys in a node's **right** subtree is strictly **larger** than the key of the node itself.

<div class="mermaid" align="center">
graph TB;
  subgraph Binary Search Tree
    A((5))-->B((4))
    A-->C((7));
    B-->E((2))
    E-->P((1))
    E-->Q((3))
    B-->F((5))
    C-->H((6))
  end
</div>

Perhaps at first, this may seem like a rather arbitrary definition. But indeed, it proves quite useful. 
### Adding a Node

### Adding a Node Complexity
Suppose we build a BST from a random permutation. Let $q(n)$ be the average number of nodes on the path from the root down to an arbitrary node in the BST.

<div class="claim">
$q(n) \le 2 \cdot H_n$, where $H_n$ is the $n$th Harmonic number.
</div>
<div class="proof">
\begin{align}
q(n) &= 1 + \frac{1}{n^2} \sum_{x = 1}^n \left( \sum_{r = 1}^{x - 1} q(x - 1) + \sum_{r = x + 1}^n q(n - x) \right) \newline
&= 1 + \frac{1}{n^2} \sum_{x = 1}^n q(x - 1) \cdot (x - 1) + q(n - x) \cdot (n - x) \newline
&=  1 + \frac{2}{n^2} \sum_{x = 1}^{n - 1} q(x) \cdot x
\end{align}
With a recurrence relation for $q$ under our belt, the next natural step is to bound $q$.

We will now prove using the method of mathematical induction that $q_n \le 2 \cdot H_n$. We can verify the base case, when $n = 1$, quite easily because $q_1 = 1 \le 2 \cdot H_1 = 2$. As for the inductive step:
\begin{align}
q(n) &= 1 + \frac{2}{n^2} \sum_{x = 1}^{n - 1} q(x) \cdot x \newline
&\le 1 + \frac{2}{n^2} \sum_{x = 1}^{n - 1} 2 x H_x \newline
&= 1 + \frac{4}{n^2} \sum_{x = 1}^{n - 1} x \sum_{i = 1}^{x} \frac{1}{i} \newline
&= 1 + \frac{4}{n^2} \sum_{i = 1}^{n - 1} \sum_{x = i}^{n - 1} \frac{x}{i} \newline
&= 1 + \frac{4}{n^2} \sum_{i = 1}^{n - 1} \frac{1}{i} \sum_{x = i}^{n - 1} x \newline
&= 1 + \frac{4}{n^2} \sum_{i = 1}^{n - 1} \frac{1}{i} \left( \binom{n}{2} - \binom{i}{2} \right) \newline
&= 1 + \frac{4}{n^2} \binom{n}{2} H_{n - 1} - \frac{4}{n^2}\sum_{i = 1}^{n - 1} \frac{1}{i} \binom{i}{2} \newline
&= 1 + \frac{2 (n - 1)}{n} H_{n - 1} - \sum_{i = 1}^{n - 1} \frac{i - 1}{2} \newline
&= 1 + 2H_{n - 1} - \frac{2}{n} H_{n - 1} - \frac{2\binom{n - 1}{2}}{n^2} \newline
&= 1 + 2H_{n - 1} - \frac{2}{n} H_{n - 1} - \frac{n - 1}{n} \newline
&= \frac{1}{n} + 2H_{n - 1} - \frac{2}{n} H_{n - 1} \newline
&\le 2H_n,
\end{align}
from which it follows that indeed $q(n) \le 2 \cdot H_n$ by induction.
</div>

### Removing a Node 

### Sample Problem: Kth Smallest Element in BST
See <a href="https://leetcode.com/problems/kth-smallest-element-in-a-bst/"> this LeetCode problem for the problem statement.



### Finding the kth smallest element
It turns out that we can recursively find the $k$th smallest key (0-indexed) in our binary search tree in $\mathcal{O}(\text{depth})$, if we know the size of the subtrees at each node. To do so, consider the following algorithm:
- Initialize our current node `cur` to be the tree's root.
- If the subtree size of the left child of `cur` is less than $k$, then we know that the $k$th smallest element lies in the left subtree of `cur`, so we can recurse to `cur = cur.left`.
- If the subtree size of the left child of `cur` is equal to $k$, then we know that our current node has the $k$th smallest key. Return `cur`.
- If the subtree size of the right child of `cur` is greater than $k$, then we know that the $k$th smallest element is in the right subtree of `cur`. Thus, we can recursive to `cur = cur.right` and set $k = k - 1$ - `cur.right.size`. 

### Problems
- <a href = "https://leetcode.com/problems/kth-smallest-element-in-a-bst/">Kth Smallest Element in a BST</a>
- 

# Treaps
In a **treap**, each node has two values:
- A a random ```priority```. 
- A ```value```.

```cpp
template <typename T>
struct Node {
    T x; //key
    T y; //order in which it is put into binary tree
    Node* left; //left child
    Node* right; //right child
    Node (int ind) { //randomly assign order index
        this->x = ind, this->y = rand() % ((int)1e9 + 7), this->left = this->right = nullptr;
    }
};
```

The values in a treap satisfy the binary search property, and the priorities in a treap satisfy the min-heap property. 

There are two simple, yet powerful, operations treaps can do: splitting and merging.
- For any value $x$, you can split a treap into two treaps: one with keys $\le x$ and another with keys $> x$.
- If all keys in one treap are strictly smaller than all keys in another treap, then we can merge those two treaps.

The worst case time complexity for both of these operations is $\mathcal{O}(N)$, but on average, they run in $\mathcal{O}(\log N)$, making them extremely fast in practice. 

# Splitting
Suppose we want to split the treap into two treaps: one with keys less than or equal to $x$ (```left```) and another with keys greater than $x$ (```right```). We can create a ```split``` function recursively:
- If the key of our current node ```root``` is less than or equal to $x$: 
  - Suppose that calling the ```split``` function on the right child of ```root``` produces ```left'``` and ```right'```. Then, we know that ```right = right'```; further, ```left``` contains ```left'```, the treap ```root->left```, and the .
- If the key of our current node ```root``` is greater than $x$:
  - 

```cpp
pair<Node*, Node*> split (Node* node, int x) { //<= x and >= x
    if (node->x <= x) {
        if (!node->right)
            return make_pair(node, nullptr);
        auto p = split(node->right, x);
        node->right = p.first;
        return make_pair(node, p.second);
    } else {
        if (!node->left)
            return make_pair(nullptr, node);
        auto p = split(node->left, x);
        node->left = p.second;
        return make_pair(p.first, node);
}
```
# Merging
```cpp
Node* merge (Node* node1, Node* node2) {
    if (!node1)
        return node2;
    if (!node2)
        return node1;
    if (node1->y < node2-> y) {
        node1->right = merge(node1->right, node2);
        return node1;
    } else {
        node2->left = merge(node1, node2->left);
        return node2;
    }
}
```
# Uses
## Static Range Sum Queries
Suppose we have a fixed array $a = [a_1, a_2, a_3, \dots a_n]$ and $q$ online queries $[l_i, r_i]$ which ask us to evaluate $\sum_{x = l_i}^{r_i} a_x$. That is, we have multiple queries asking us to find the sum of elements with indices in a given range.

This may seem like a problem completely unrelated to treaps, but it can be solved using treaps in $\mathcal{O}(N \log N + Q \log N)$. 

In each node ```node``` of the treap, store an additional parameter ```sum```, which stores the sum of the keys in all nodes of the subtree of ```node```. That is, each node will now have three parameters:

- ```sum```, which stores the sum of values of all nodes in the subtree.
- A random ```priority```
- An ```index```
- A ```value``` defined as ```a[index]```.

## Dynamic Range Sum Queries
Suppose that we instead have a dynamic array. That is, in addition to online queries $[l_i, r_i]$, we may also have online queries $\text{[index, y]}$ asking us to change the value of ```a[index]``` to a new value ```y```.

This problem can also be solved with treaps with just a simple modification!
## Reversal
## Range Updates
## Cut and Paste

<div class = "lineComment">
Like this
</div>